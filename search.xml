<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[git commit message 编写规范]]></title>
    <url>%2F2018%2F05%2F13%2Fgit-commit-message-format%2F</url>
    <content type="text"><![CDATA[git是软件开发过程中必不可少的代码管理工具，在每次提交新代码时，需要写一些信息表示本次提交所改动的内容。为了方便日后的管理与迭代，commit message最好能有一些固定的格式，让人一眼就能知道每一次提交所做的修改。本文分享一下开源社区常用的代码提交规范，仅供参考。 完整的commit message格式如下: 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&lt;BLANK LINE&gt;&lt;body&gt;&lt;BLANK LINE&gt;&lt;footer&gt; 有三个大的部分，分别是Header(第一行)、Body和Footer。在Header部分，type字段用于说明commit的类别，允许使用下面7个标识符: feat: 增加新功能 fix: 修复bug docs: 编写文档 style: 变换代码风格(不影响代码运行的变动) refactor: 代码重构(对代码结构有大的改动，但不影响运行) test: 增加测试代码 chore: 辅助工具的变动 scope字段用于说明本次commit所影响的范围，比如视图层、数据模型或者路由模块等，是一个可选参数。 subject字段是本次commit的一个概要，需要用最简洁的语言来说明本次修改的内容。 在Body部分，可以使用多行文本详细地说明本次提交所改动的一些细节，从而帮助后续的使用者们更好地了解代码的内容。 Footer部分一般只用于两种情况，一是不兼容变动，如果本次的commit与前一个版本的代码无法兼容，那么Footer部分需要以BREAKING CHANGE开头，后面描述本次变动的详细情况以及迁移到新版本代码的方法。 二是关闭Issue，如果本次commit是针对某个Issue，可以在Footer部分以Close开头，后面用#号标识对应的Issue号码。 以上所说的就是完整的commit message的规范写法，在实际开发中，为了提高效率，也可以丢弃Body和Footer部分，在Header的subject字段中写入必要的说明，同时可以加入Fix和Close等标明修复某个bug或者关闭某个Issue，这样既简洁又达到了日常实用的目的。当然团队内部有时候也会针对开发的项目给出对应的要求，总的来说都是为了让开发过程更加的高效和便捷。 参考资料：Commit message 和 Change log 编写指南规范的Commit message提交格式]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kibana和Elasticsearch允许外网访问]]></title>
    <url>%2F2018%2F05%2F12%2Fkibana-es-access-connection%2F</url>
    <content type="text"><![CDATA[ElasticSearch(下文简称ES)是一个基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎。Kibana则是一款开源的分析与可视化平台，可以用来与ES进行交互，通过可视化界面来查看和操作ES中的数据。默认情况下这两个软件只允许通过本机localhost访问。本文分享如何通过设置使得这两者可以被同一网络中的其他机器访问。 我们先看一下在使用默认设置时，当我们尝试通过IP地址去访问ES的服务(在9200端口)时，会得到如下结果 12$ curl 10.0.0.141:9200curl: (7) Failed to connect to 10.0.0.141 port 9200: Connection refused 从提示结果可以看到，ES服务拒绝了我们的访问，这是因为ES服务默认监听的主机是localhost，如果希望通过IP进行访问，需要设置其监听0.0.0.0。这个地址表示的是所有未知的主机和目的网络的集合。对于Kibana也是一样的道理，因此以下只阐述ES的配置方法 具体来说，分为两步走，首先要找到ES的配置文件，在不同的系统中配置文件存放的路径也不同。对于Mac系统来说，如果是通过brew安装的ES，那么可以通过以下命令来查看配置文件的位置 12345678910111213141516171819202122$ brew info elasticsearchelasticsearch: stable 6.2.3, HEADDistributed search &amp; analytics enginehttps://www.elastic.co/products/elasticsearch/usr/local/Cellar/elasticsearch/5.6.3 (217 files, 124MB) * Built from source on 2017-11-07 at 16:32:00From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/elasticsearch.rb==&gt; RequirementsRequired: java = 1.8 ✔==&gt; Options--HEAD Install HEAD version==&gt; CaveatsData: /usr/local/var/lib/elasticsearch/elasticsearch_gao-yimei/Logs: /usr/local/var/log/elasticsearch/elasticsearch_gao-yimei.logPlugins: /usr/local/var/elasticsearch/plugins/Config: /usr/local/etc/elasticsearch/To have launchd start elasticsearch now and restart at login: brew services start elasticsearchOr, if you don't want/need a background service you can just run: elasticsearch 结果中的Config标识了配置文件所在的目录。进入该目录，可以看到一个名为elasticsearch.yml的配置文件，通过less命令查看并搜索host可以找到一个network.host的配置参数，我们只需要将该参数前的#号去掉，并将该值设置为0.0.0.0并保存即可。注意第一个0与参数名之间需要有一个空格，这是配置文件的格式要求 修改完成后，还需要一步，那就是重新启动ES服务器，对于Mac用户，可以通过以下命令重启服务： 1234$ brew services restart elasticsearch Stopping `elasticsearch`... (might take a while)==&gt; Successfully stopped `elasticsearch` (label: homebrew.mxcl.elasticsearch)==&gt; Successfully started `elasticsearch` (label: homebrew.mxcl.elasticsearch) 等待两三分钟后，服务即可稳定，此时再通过IP访问ES服务，就可以正常使用 值得注意的是，当我们这样设置以后，同一网络中的所有设备都能随意地访问到本机的ES服务，包括所有存储在ES中的数据，这是一个比较危险的操作，因此请谨慎使用。另外，对于其他很多不同的软件，也存在这种默认情况下不允许通过IP访问的问题，设置的方式和ES大同小异，可以参考上述的操作流程。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>ES</tag>
        <tag>Kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac设置固定IP地址]]></title>
    <url>%2F2018%2F05%2F12%2Fset-fixed-ip-address-on-mac%2F</url>
    <content type="text"><![CDATA[在日常的开发过程中，有时候为了方便程序的调试，需要将本机的IP地址固定。本文分享下在Mac系统中固定IP地址的方法，仅供参考。 1、点击桌面上的系统偏好设置图标，在打开的设置界面点击网络图标 2、在网络设置界面，点击高级，进入高级设置 3、在高级设置界面，进入TCP/IP选项，点击配置IPv4选项，在下拉框中选择手动，同时设置对应的IPv4地址和路由器地址。注意必须保证此处设置的IPv4地址是内网中还未被使用的，如已被占用会提示错误，需要重新进行填写 4、还是在当前页面，进入DNS选项，在DNS服务器这一栏中添加本地的DNS服务器地址，可能需要问一下网络管理员 5、设置完成，点击右下角好，再继续点击右下角应用，然后重新连接网络，即可使用固定的IP地址进行程序开发]]></content>
      <categories>
        <category>daily</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【已解决】PyCharm证书过期]]></title>
    <url>%2F2018%2F04%2F29%2Fpycharm-license-expired%2F</url>
    <content type="text"><![CDATA[问题描述今天打开PyCharm的时候弹出提示框 Your license has expired，表示证书到期了，无法继续使用软件。之前使用的证书是在学校的时候注册的学生账号，也就是以.edu.cn结尾的账号。现在需要寻找一种新的认证方式。 解决方案PyCharm属于JetBrains的一员，这个系列的软件的认证方式有三种，分别是账号登录、激活码和授权服务器。对于在校的学生用户，可以使用.edu后缀的邮箱注册JetBrains账号即可免费使用。激活码则需要在官网上购买，也可以在网上找一些共享的激活码，但使用期限和稳定性无法保证，也并非官方推荐的方法。还有一种方法就是通过授权服务器，这种方法相当于把大量可用的license聚集起来，然后在多个用户间共享，每个用户每次分配到的license可能都不一致。关于授权服务器的更多信息，可以查看官网文档 官方提供了一些可用的授权服务器地址，一般是需要付费的。当然也可以自己来搭建授权服务器。这里就分享一下网友栗小米搭建的授权服务器地址:https://www.imsxm.com，亲测可用，稳定性很高，而且还会保持更新，可以说是非常赞了！ 具体的使用方法很简单，打开软件后，在授权页面勾选License server选项，在地址栏输入http://idea.imsxm.com/，再点击右下角的Activate即可。重启软件，弹出提示框Your copy is licensed to imsxm.com，表示软件已经认证成功。也可以在软件内点击菜单栏上的Help选项，单击最后一个选项Register，即可修改认证的方式。 如果各位觉得好用，记得给可爱的栗小米同学打赏哦，多多支持开源软件！当然，有条件的朋友还是尽可能地购买官方激活码啦，毕竟码农不易，且行且珍惜~ 参考JetBrains 授权服务器]]></content>
      <categories>
        <category>daily</category>
      </categories>
      <tags>
        <tag>JetBrains</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gensim计算文档相似度]]></title>
    <url>%2F2018%2F04%2F23%2Fgensim-doc-similarity%2F</url>
    <content type="text"><![CDATA[gensim是一个基于Python语言的开源工具集，用于处理向量空间模型(vector space modeling)和话题模型(topic modeling)的相关问题。本文分享如何使用gensim工具来计算两篇中文文档的相似度。 首先我们要生成一些中文文档。下面的代码生成一个名为documents的文档列表，由于是演示，这里的每个文档中只有几个词语。关于如何对原始的字符串做分词操作，可以参考jieba 1234567891011from gensim import corporafrom pprint import pprintdocuments = ["你好 好的 不错 笨蛋", "笨蛋 傻瓜 傻子 哈哈", "好的 不错 你好 哈哈", "有趣 可以 好的 不错 还行", "傻瓜 傻子 二货 还行", "可以 好的 不错 哈哈", "有趣 有趣 哈哈 哈哈"]texts = [[word for word in document.split()] for document in documents]pprint(texts) [[&apos;你好&apos;, &apos;好的&apos;, &apos;不错&apos;, &apos;笨蛋&apos;], [&apos;笨蛋&apos;, &apos;傻瓜&apos;, &apos;傻子&apos;, &apos;哈哈&apos;], [&apos;好的&apos;, &apos;不错&apos;, &apos;你好&apos;, &apos;哈哈&apos;], [&apos;有趣&apos;, &apos;可以&apos;, &apos;好的&apos;, &apos;不错&apos;, &apos;还行&apos;], [&apos;傻瓜&apos;, &apos;傻子&apos;, &apos;二货&apos;, &apos;还行&apos;], [&apos;可以&apos;, &apos;好的&apos;, &apos;不错&apos;, &apos;哈哈&apos;], [&apos;有趣&apos;, &apos;有趣&apos;, &apos;哈哈&apos;, &apos;哈哈&apos;]] 然后我们要对原始的文档做一些预处理。这里我们统计了每个词语出现的次数，移除了只出现一次的词语，因为这些词语通常不会对计算文档相似度产生任何贡献。其他的预处理操作还包括移除数字、字母以及标点符号等，这里我们没有展示，如果实际中遇到可以进行相应的处理。 1234567from collections import defaultdictfrequency = defaultdict(int)for text in texts: for token in text: frequency[token] += 1texts = [[token for token in text if frequency[token] &gt; 1] for text in texts]pprint(texts) [[&apos;你好&apos;, &apos;好的&apos;, &apos;不错&apos;, &apos;笨蛋&apos;], [&apos;笨蛋&apos;, &apos;傻瓜&apos;, &apos;傻子&apos;, &apos;哈哈&apos;], [&apos;好的&apos;, &apos;不错&apos;, &apos;你好&apos;, &apos;哈哈&apos;], [&apos;有趣&apos;, &apos;可以&apos;, &apos;好的&apos;, &apos;不错&apos;, &apos;还行&apos;], [&apos;傻瓜&apos;, &apos;傻子&apos;, &apos;还行&apos;], [&apos;可以&apos;, &apos;好的&apos;, &apos;不错&apos;, &apos;哈哈&apos;], [&apos;有趣&apos;, &apos;有趣&apos;, &apos;哈哈&apos;, &apos;哈哈&apos;]] 接着我们生成了包含所有词语的词典，为后面的计算做准备。在实际情况中，词典通常会很大，为了避免重复计算，可以将词典保存下来。 123dictionary = corpora.Dictionary(texts)dictionary.save('sample.dict')print(dictionary) Dictionary(10 unique tokens: [&apos;不错&apos;, &apos;你好&apos;, &apos;好的&apos;, &apos;笨蛋&apos;, &apos;傻子&apos;]...) 有了前一步生成的词典，我们就可以将每个词语转化成一个索引，表示该词语在所有文档中出现的次序，然后每个文档就可以转化成一个索引的列表，比如这里的第一个文档表示为[(0, 1), (1, 1), (2, 1), (3, 1)]，它的含义是在第一篇文档中，第0个词语(也就是“你好”)出现了一次，第一个词语(也就是“好的”)出现了一次，依次类推。 123corpus = [dictionary.doc2bow(text) for text in texts]corpora.MmCorpus.serialize('sample.mm', corpus)pprint(corpus) [[(0, 1), (1, 1), (2, 1), (3, 1)], [(3, 1), (4, 1), (5, 1), (6, 1)], [(0, 1), (1, 1), (2, 1), (6, 1)], [(0, 1), (2, 1), (7, 1), (8, 1), (9, 1)], [(4, 1), (5, 1), (9, 1)], [(0, 1), (2, 1), (6, 1), (7, 1)], [(6, 2), (8, 2)]] 然后我们可以调用gensim中的tf-idf模块来进一步对每个单词计算权重。关于tf-idf的计算方法，可以参考维基百科 1234from gensim import models, similaritiestf_idf = models.TfidfModel(corpus)vec = [(0, 1), (5, 1), (7, 1)]print(tf_idf[vec]) [(0, 0.3011997233053068), (5, 0.6742695034927825), (7, 0.6742695034927825)] 现在，我们可以开始计算两个文档的相似度了。这里我们采用了余弦相似度作为衡量指标，当然还有其他的方式，可以参考文本相似度计算方法研究综述 123index = similarities.SparseMatrixSimilarity(tf_idf[corpus], num_features=10)sims = index[tf_idf[vec]]print(sims) [0.08686648 0.37695488 0.10641449 0.43870124 0.38928968 0.63969857 0. ] 我们还可以将整个相似度矩阵打印出来，就可以看到前面我们所准备的七篇文档两两之间的相似度。1print(index[tf_idf[corpus]]) [[1. 0.3609379 0.71441036 0.13975498 0. 0.20378576 0. ] [0.3609379 1.0000001 0.08823138 0. 0.64554304 0.08823138 0.10185669] [0.71441036 0.08823138 1.0000001 0.17120475 0. 0.37446705 0.1440983 ] [0.13975498 0. 0.17120475 1. 0.31315398 0.60019135 0.4952337 ] [0. 0.64554304 0. 0.31315398 0.99999994 0. 0. ] [0.20378576 0.08823138 0.37446705 0.60019135 0. 1. 0.1440983 ] [0. 0.10185669 0.1440983 0.4952337 0. 0.1440983 0.99999994]] 本文中的代码使用Jupyter Notebook编写，需要的朋友可以直接到github上查看。]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>gensim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【已解决】Mac安装Jupyter notebook出错的问题]]></title>
    <url>%2F2018%2F04%2F18%2Fjupyter-notebook-install-error%2F</url>
    <content type="text"><![CDATA[问题描述在Mac上安装Jupyter Notebook，按照Jupyter官网文档进行安装，命令如下12python3 -m pip install --upgrade pippython3 -m pip install jupyter 安装完成后执行jupyter notebook命令时提示1Error executing Jupyter command 'notebook': [Errno 2] No such file or directory 相关的环境参数 操作系统：macOS 10.13.4 Python版本：Python 3.6.3 解决方案依次输入以下两条命令，若提示权限不足在前面加sudo12pip3 install ipython[notebook]pip3 install jupyter]]></content>
      <categories>
        <category>daily</category>
      </categories>
      <tags>
        <tag>Jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AUC值的含义与计算方法]]></title>
    <url>%2F2018%2F04%2F11%2Fauc-meaning-calculation%2F</url>
    <content type="text"><![CDATA[引言在机器学习领域，AUC值经常用来评价一个二分类模型的训练效果，对于许多机器学习或者数据挖掘的从业者或在校学生来说，AUC值的概念也经常被提起，但由于大多数时候我们都是借助一些软件包来训练机器学习模型，模型评价指标的计算往往被软件包所封装，因此我们常常会忽略了它们的具体意义，这在有些时候会让我们对于手头正在进行的任务感到困惑。笔者也曾遇到类似的问题，因此希望借由本文来梳理下AUC值的意义与计算方法，通过实际的例子帮助读者加深理解，同时给出了使用scikit-learn工具库计算AUC值的方法，供各位参考。 定义AUC的全称是Area under the Curve of ROC，也就是ROC曲线下方的面积。这里出现了另一个概念，就是ROC曲线。那么ROC曲线是个什么东西呢？我们参看下维基百科上的定义：在信号检测理论中，接收者操作特征曲线（receiver operating characteristic curve，或者叫ROC曲线）是一种坐标图式的分析工具，用于 (1) 选择最佳的信号侦测模型、舍弃次佳的模型。 (2) 在同一模型中设定最佳阈值。这个概念最早是由二战中的电子工程师和雷达工程师发明的，用来侦测战场上的敌军载具。概括来说，可以把ROC曲线理解为一种用于统计分析的图表工具。 那么具体到机器学习的理论中，ROC曲线该怎么理解呢？首先，需要指出的是，ROC分析的是二元分类模型，也就是输出结果只有两种类别的模型，比如：（阳性/阴性）（有病/没病）（垃圾邮件/非垃圾邮件）。在二分类问题中，数据的标签通常用（0/1）来表示，在模型训练完成后进行测试时，会对测试集的每个样本计算一个介于0~1之间的概率，表征模型认为该样本为阳性的概率，我们可以选定一个阈值，将模型计算出的概率进行二值化，比如选定阈值=0.5，那么当模型输出的值大于等于0.5时，我们就认为模型将该样本预测为阳性，也就是标签为1，反之亦然。选定的阈值不同，模型预测的结果也会相应地改变。二元分类模型的单个样本预测有四种结果： 真阳性（TP）：判断为阳性，实际也是阳性。 伪阳性（FP）：判断为阴性，实际却是阳性。 真阴性（TN）：判断为阴性，实际也是阴性。 伪阴性（FN）：判断为阴性，实际却是阳性。 这四种结果可以画成2 × 2的混淆矩阵： 有了混淆矩阵，就可以定义ROC曲线了。ROC曲线将假阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴。其中： TPR：在所有实际为阳性的样本中，被正确地判断为阳性的样本比率。 FPR：在所有实际为阴性的样本中，被错误地判断为阳性的样本比率。 TPR = TP / (TP + FN) FPR = FP / (FP + TN) 给定一个二分类模型和它的阈值，就可以根据所有测试集样本点的真实值和预测值计算出一个 (X=FPR, Y=TPR) 坐标点，这也就是绘制单个点的方法。那整条ROC曲线又该怎么画呢？具体方法如下： 在我们训练完一个二分类模型后，可以使用该模型对测试集中的全部样本点计算一个对应的概率值，每个值都介于0~1之间。假设测试集有100个样本点，我们可以对这100个样本的预测值从高到低排序，然后依次取每个值作为阈值，一旦阈值确定我们就可以绘制ROC曲线上的一个点，按照这种方法依次将100个点绘制出来，再将各个点依次连接起来，就得到了我们想要的ROC曲线！ 然后再回到最初的问题，AUC值其实就是ROC曲线下方所覆盖的面积，当我们绘制出ROC曲线之后，AUC的值自然也就计算好啦。 示例这里引用上海交大张伟楠老师机器学习课件中的例子来说明： 如上图所示，我们有8个测试样本，模型的预测值（按大小排序）和样本的真实标签如右表所示，绘制ROC曲线的整个过程如下所示： 令阈值等于第一个预测值0.91，所有大于等于0.91的预测值都被判定为阳性，此时TPR=1/4，FPR=0/4，所有我们有了第一个点（0.0，0.25） 令阈值等于第二个预测值0.85，所有大于等于0.85的预测值都被判定为阳性，这种情况下第二个样本属于被错误预测为阳性的阴性样本，也就是FP，所以TPR=1/4，FPR=1/4，所以我们有了第二个点（0.25，0.25） 按照这种方法依次取第三、四…个预测值作为阈值，就能依次得到ROC曲线上的坐标点（0.5，0.25）、（0.75，0.25）…（1.0，1.0） 将各个点依次连接起来，就得到了如图所示的ROC曲线 计算ROC曲线下方的面积为0.75，即AUC=0.75 代码在清楚了AUC值的计算原理后，我们再来看看如何在代码中实现它。通常很多的机器学习工具都封装了模型指标的计算，当然也包括AUC值。这里我们来一起看下scikit-learn中AUC的计算方式，如下所示： 123456&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; from sklearn.metrics import roc_auc_score&gt;&gt;&gt; y_true = np.array([0, 0, 1, 1])&gt;&gt;&gt; y_scores = np.array([0.1, 0.4, 0.35, 0.8])&gt;&gt;&gt; roc_auc_score(y_true, y_scores)0.75 可以看出，使用scikit-learn工具提供的roc_auc_score函数计算AUC值相当简单，只需要提供样本的实际标签和预测值这两个变量即可，大大方便了我们的使用，真心感谢这些开源软件的作者们！ 总结看到这里的小伙伴们是不是对AUC值的概念有了更好的理解呢。总的来说，AUC值就是一个用来评价二分类模型优劣的常用指标，AUC值越高通常表明模型的效果越好，在实际使用中我们可以借助软件包的相应函数进行快速计算。如果各位还有一些问题或者是对文章中的某些部分有疑问，欢迎在评论区讨论。 参考ROC曲线维基百科张伟楠老师课件机器学习和统计里面的auc怎么理解？ - 知乎]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nodejs调用SendCloud邮件API2.0]]></title>
    <url>%2F2018%2F04%2F07%2Fnodejs-sendcloud-mail-api%2F</url>
    <content type="text"><![CDATA[SendCloud作为专业的第三方邮件发送服务提供商，具有高效和稳定的特点，很好地满足平时业务中的相关需求。前一阵在使用时发现原有的邮件API接口升级到2.0了，对于普通发送功能而言，主要的区别在于传递的参数从body参数变成了query参数，由于SendCloud官网还未给出nodejs版本的示例代码，故在此分享，供各位参考。如果需要查看相关文档，请至SendCloud官方文档页 123456789101112131415161718192021222324252627282930313233var http = require('http');var param = &#123; apiUser: 'your api user', apiKey: 'related api key', from: 'service@example.com', fromName: '客服测试', subject: '测试接口功能', to: 'somebody@example.com', html: '测试SendCloud邮件API，收到请勿回复，谢谢。'&#125;;data = require('querystring').stringify(param);var options = &#123; host: "api.sendcloud.net", port: 80, path: "/apiv2/mail/send", method: "POST"&#125;;options.path = options.path + '?' + data;var req = http.request(options, function(res) &#123; var responseStr = ''; res.on('data', function (chunk) &#123; responseStr += chunk; &#125;); res.on('end', function() &#123; console.log(responseStr); &#125;);&#125;);req.end(); 实际使用时，只需要修改参数param的内容填入对应的值即可。有一个值得注意的地方是，新版的邮件发送功能多了一个设置，在首页 -&gt; 邮件 -&gt; 发送设置页面，有一个From开关的设置，它的意思是“如果开启此开关后，自主填写的From的域名后缀不会生效，将和发信域名的后缀保持一致”。所以如果我们需要使用自主填写的From域名，需要先将这个开关设为OFF状态。但这其实并非SendCloud推荐的做法，如果我们需要用自己的域名来发送，最好还是按照SendCloud相应的流程认证之后再使用比较好。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网页短链接的实现原理]]></title>
    <url>%2F2018%2F03%2F31%2Fshort-link-implement%2F</url>
    <content type="text"><![CDATA[网页短链接是指将原本较长的网址转化成较短的网址，从而便于用户的记忆与社交软件上的传播。很多互联网公司都提供了生成短链接的服务，比如新浪微博短网址服务等，本文就来聊聊实现短链接服务的基本原理。 我们不妨先来看一下短链接服务的整个流程，以前面提到的微博短网址服务为例。用户输入想要缩短的长网址，转化后得到一个以http://t.cn开头的短网址，然后用户将该链接通过微信或者微博等方式分享给朋友，其他人点击之后即可进入原本长网址所对应的页面。整个流程如下图所示： 从图中可以很清楚地看到，实现短链接服务的关键是两个步骤：1、如何把一个任意长的字符串转化成一个较短的字符串；2、从短网址如何还原出长网址。第一个问题很容易让人想到哈希算法，通过一定的方式将任意长的文本转化成一个固定长度的字符串，只要目标字符串的长度适当，那么不同的输入几乎不可能对应同一个字符串。不过这么做有个缺点就是无法从得到的结果还原输入的字符串，因此不适用于我们的场景。但基于哈希算法的思想，我们可以设计一种以多进制为基础的算法完成这个任务。 具体而言，我们可以创建一个用于保存长网址的数据表，比如就叫Url，这张表很简单，只需要两个字段，一个主键用于保存id，一个url字段用于存放原始的长网址，每个长网址都在这张表有一条记录。当进行长网址转换时，先检查数据表中是否存在该长网址，若是直接获取该记录的id，否则在数据表中创建一条新记录，并返回其id。对于这个id，我们可以得到一个多进制表示下的新值，比如在以“0-9a-z”这36个字符表示的36进制中，一亿这个数字可以被表示成1njchs，只需要6个字符即可，将这6个字符拼接到准备好的域名后即可得到一个对应的短网址返回给用户。由于一亿个网址只需要6个字符，因此这种方式足够满足大部分网站的需求。 而当用户点击了我们生成的短网址后，只需要将代表多进制的这部分提取出来，还原成十进制的数字后查表即可得到原始的长网址，再根据网址做一个重定向即可让用户访问到原始的网页。具体的实现可以参考下面的typescript代码 1234567891011121314151617181920212223// 将原始的长链接通过36进制转化为短链接export async function long2short(url: string) &#123; if (!url.startsWith('http://') &amp;&amp; !url.startsWith('https://')) &#123; throw new Error('Invalid url'); &#125; if (url.startsWith(config.shortLinkBaseUrl)) &#123; return url; &#125; let item = await Url.getByUrl(url); if (!item) &#123; item = await Url.create(url); &#125; return config.shortLinkBaseUrl + item.id.toString(36);&#125;// 将短链接还原为真实的长链接export async function short2long(url: string) &#123; let item = await Url.select(Number.parseInt(url, 36)); if (!item) &#123; throw new Error('Invalid url'); &#125; return item.url;&#125; 这里的config.shortLinkBaseUrl也就是我们用来做短链接服务的域名，在前面的例子中就是http://t.cn，我们需要在这个域名对应的服务器内实现短链接的服务，同时这个域名本身不能太长，否则就失去了它的意义。另外还有一点值得注意，就是在根据长网址去数据表查找它是否存在时，因为长网址可以任意长，因此直接用它作为索引在数据表中查找的话效率较低，可以考虑在表中增加一个hash字段，保存长网址的哈希值，并通过查找哈希值来判断条目是否存在，提高查找的效率。 以上就是短链接服务的基本实现方法，最核心的其实就是多进制的使用，有兴趣的朋友可以自己动手试试看，有任何问题欢迎留言交流。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的Bash快捷键]]></title>
    <url>%2F2018%2F01%2F30%2Fbash-shortcut-key%2F</url>
    <content type="text"><![CDATA[Bash命令行是程序员日常开发中必备的好帮手，掌握一些有效且常用的快捷键可以帮助我们更好地使用bash这个工具，提高工作效率。本文根据笔者个人的经验，总结了一些针对Linux系统的Bash快捷键操作，供各位参考。 Ctrl + L: 清屏，强迫症患者必备Ctrl + R: 逆向搜索命令的历史记录Ctrl + C: 终止命令，中断一个前台作业Ctrl + A: 光标移动到命令行首Ctrl + E: 光标移动到命令行尾Ctrl + U: 从光标处删除至命令行首Ctrl + K: 从光标处删除至命令行尾Ctrl + W: 从光标处删除至字首Alt + D: 从光标处删除至字尾Ctrl + Shift + C: 在bash中复制Ctrl + Shift + V: 在bash中粘贴方向键上↑: 查看历史中的上一条命令方向键下↓: 查看历史中的下一条命令Command -h: 查看某个命令的帮助文档 虽然数量不多，但都很常用，牢记这几个快捷操作，相信对开发会有帮助的。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL基本用法]]></title>
    <url>%2F2018%2F01%2F11%2Fpostgresql-basic-usage%2F</url>
    <content type="text"><![CDATA[前言PostgreSQL是一个开源的、对象关系型数据库管理系统（ORDBMS）。本文旨在介绍PostgreSQL（下文简称pg）的一些基本操作，供初学者参考和查阅。需要注意的是，以下所有操作是在Ubuntu 16.04中进行的，使用的pg版本是9.6。对于不同的操作系统和版本，操作流程可能有些许的差别，具体可以参看后面给出的参考文档中的内容。 安装Ubuntu默认集成了pg，可以通过命令行直接安装 以下命令分别安装pg的客户端和服务端12$ sudo apt-get install postgresql-client$ sudo apt-get install postgresql 安装完成后，通过以下命令即可启动pg1$ sudo service postgresql start 相应的，只要将这里的start改为stop和restart，就可以实现服务的停止和重启 创建一个数据库在初次安装完成后，pg默认已经进行了如下的操作：创建了一个名为postgres的数据库用户和一个名为postgres的数据库，同时还创建了一个名为postgres的Linux系统用户。实际上，这里创建的postgres数据库用户拥有超级管理员身份，可以访问我们后面所创建的所有数据库，同时可以进行创建新数据库用户和修改用户密码等操作。 为了操作数据库，我们通常需要先登录控制台1$ sudo -u postgres psql 这条命令表示Linux用户postgres以超级用户postgres的身份登录了名为postgres的数据库，因为是Ubuntu系统，所以默认这个时候是不需要输入密码的，直接进入了pg的控制台1postgres=# 通常我们会在登录后先给postgres用户设置一下密码1postgres=# \password postgres 两次输入相同的密码后即可修改成功 因为postgers用户具有很高的权限，通常我们不会直接以这个身份登录，而是会另外创建一个新用户，比如创建一个和当前系统用户同名的数据库用户1postgres=# CREATE USER dbuser WITH PASSWORD 'password'; 然后我们可以为这个新用户创建一个数据库1postgres=# CREATE DATABASE exampledb OWNER dbuser; 接下来我们就可以使用刚才创建的用户登录控制台并连接到创建的数据库中来进行一系列的操作了1$ psql -U dbuser -d exampledb 常用的控制台命令12345678910\password 设置密码\q 退出\h 查看SQL命令的解释，比如\h select\? 查看psql命令列表\l 列出所有数据库\c [database_name] 连接其他数据库\d 列出当前数据库的所有表格\d [table_name] 列出某一张表格的结构\x 对数据做展开操作\du 列出所有用户 常用的SQL语句123456789101112131415161718192021222324252627282930313233343536373839404142# 创建新表CREATE TABLE table_name(name VARCHAR(20), birth DATE);# 插入数据INSERT INTO table_name(name, birth) VALUES('欧文', '1994-08-23');# 查询记录SELECT * FROM table_name;# 更新数据UPDATE table_name set name = '勒夫' WHERE name = '欧文';# 删除记录DELETE FROM table_name WHERE name = '欧文' ;# 添加字段ALTER TABLE table_name ADD email VARCHAR(40);# 更改字段类型ALTER TABLE table_name ALTER COLUMN birth SET NOT NULL;# 设置字段默认值（注意字符串使用单引号）ALTER TABLE table_name ALTER COLUMN email SET DEFAULT 'example@example.com';# 去除字段默认值ALTER TABLE table_name ALTER email DROP DEFAULT;# 重命名字段ALTER TABLE table_name RENAME COLUMN birth TO birthday;# 删除字段ALTER TABLE table_name DROP COLUMN email;# 表重命名ALTER TABLE table_name RENAME TO backup_table;# 删除表DROP TABLE IF EXISTS backup_table;# 删除库\c postgres;DROP DATABASE IF EXISTS hello; 备份和恢复12$ pg_dump --format=t -d db_name -U user_name -h 127.0.0.1 -O -W &gt; dump.sql$ psql -h 127.0.0.1 -U user_name db_name &lt; dump.sql 参考资料 PostgreSQL官方文档 阮一峰的网路日志]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一页纸搞定git命令]]></title>
    <url>%2F2017%2F12%2F04%2Fgit-cheat-sheet-cn%2F</url>
    <content type="text"><![CDATA[本文翻译自Git cheat sheet，通过一页纸的内容搞定Git常用命令。 创建复制一个已创建的仓库： 通过 SSH1$ git clone ssh://user@domain.com/repo.git 通过 HTTP1$ git clone http://domain.com/user/repo.git 创建一个新的本地仓库:1$ git init 配置列出当前配置：1$ git config --list 列出repository配置：1$ git config --local --list 列出全局配置：1$ git config --global --list 列出系统配置：1$ git config --system --list 设置用户名：1$ git config --global user.name “[firstname lastname]” 设置用户邮箱：1$ git config --global user.email “[valid-email]” 设置git命令输出为彩色：1$ git config --global color.ui auto 配置文件Repository配置对应的配置文件路径：1/.git/config 用户全局配置对应的配置文件路径：1~/.gitconfig 系统配置对应的配置文件路径：1/etc/gitconfig 本地修改显示工作路径下已修改的文件：1$ git status 显示与上次提交版本文件的不同：1$ git diff 把当前所有修改添加到下次提交中：1$ git add . 把对某个文件的修改添加到下次提交中：1$ git add -p &lt;file&gt; 提交本地的所有修改：1$ git commit -a 提交之前已标记的变化：1$ git commit 附加消息提交：1$ git commit -m 'message here' 修改上次提交 请勿修改已发布的提交记录!!! 1$ git commit --amend 提交历史从最新提交开始，显示所有的提交记录（显示hash， 作者信息，提交的标题和时间）：1$ git log 显示所有提交（仅显示提交的hash和message）：1$ git log --oneline 显示某个用户的所有提交：1$ git log --author="username" 显示某个文件的所有修改：1$ git log -p &lt;file&gt; 谁，在什么时间，修改了文件的什么内容：1$ git blame &lt;file&gt; 分支与标签列出所有分支：1$ git branch -av 列出所有的远端分支：1$ git branch -r 切换分支：1$ git checkout &lt;branch&gt; 基于当前分支创建新分支：1$ git branch &lt;new-branch&gt; 基于远程分支创建新的可追溯的分支：1$ git branch --track &lt;remote/branch&gt; 删除本地分支:1$ git branch -d &lt;branch&gt; 强制删除一个本地分支： 将会丢失未合并的修改!!! 1$ git branch -D &lt;branch&gt; 给当前版本打标签：1$ git tag &lt;tag-name&gt; 更新与发布列出当前配置的所有远程端：1$ git remote -v 显示某个远程端的信息：1$ git remote show &lt;remote&gt; 添加新的远程端：1$ git remote add &lt;shortname&gt; &lt;url&gt; 下载远程端版本，但不合并到HEAD中：1$ git fetch &lt;remote&gt; 下载远程端版本，并自动与HEAD版本合并：1$ git pull &lt;remote&gt; &lt;branch&gt; 将本地版本发布到远程端：1$ git push &lt;remote&gt; &lt;branch&gt; 删除远程端分支：1$ git branch -dr &lt;remote/branch&gt; 发布标签:1$ git push --tags 合并与重置将分支合并到当前HEAD中：1$ git merge &lt;branch&gt; 将当前HEAD版本重置到分支中： 请勿重置已发布的提交!!! 1$ git rebase &lt;branch&gt; 丢弃某次重置：1$ git rebase --abort 解决冲突后继续重置：1$ git rebase --continue 使用配置好的merge tool 解决冲突：1$ git mergetool 在编辑器中手动解决冲突后，标记文件为已解决冲突：12$ git add &lt;resolved-file&gt;$ git rm &lt;resolved-file&gt; 撤销放弃工作目录下的所有修改：1$ git reset --hard HEAD 放弃某个文件的所有本地修改：1$ git checkout HEAD &lt;file&gt; 重置一个提交（通过创建一个截然不同的新提交）1$ git revert &lt;commit&gt; 将HEAD重置到指定的版本，并抛弃该版本之后的所有修改：1$ git reset --hard &lt;commit&gt; 将HEAD重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改：1$ git reset &lt;commit&gt; 将HEAD重置到上一次提交的版本，并保留未提交的本地修改：1$ git reset --keep &lt;commit&gt; 删除添加.gitignore文件前错误提交的文件：123$ git rm -r --cached .$ git add .$ git commit -m "remove xyz file"]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch更新同义词表]]></title>
    <url>%2F2017%2F11%2F13%2Fupdate-es-synonym%2F</url>
    <content type="text"><![CDATA[ElasticSearch是一个基于Lucene的搜索服务器，能够高效地进行查询操作。同义词表是ES中的一个辅助工具，可以增加查询操作的灵活性和实用性。在项目开发中，有时会需要更新同义词表，以提供更好的服务。 步骤0、Ubuntu 16.04操作系统中，默认情况下，ES的同义词表保存在 /etc/elasticsearch/analysis/synonym.txt 文件中，以下操作以此为例。 1、修改synonym.txt1$ sudo vim /etc/elasticsearch/analysis/synonym.txt 根据规则添加所需的同义词条目，具体规则如下图所示，或查看文档https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-synonym-tokenfilter.html 2、重启ES服务1$ sudo systemctl restart elasticsearch 3、至此，同义词表更新完毕，可以通过观察程序的运行效果来验证是否成功。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下安装Elasticsearch极简指南]]></title>
    <url>%2F2017%2F11%2F07%2Finstall-elasticsearch-osx%2F</url>
    <content type="text"><![CDATA[Elasticsearch(以下简称ES)是一个面向文档的实时分布式搜索和分析引擎。本文是在Mac系统下使用Homebrew安装ES+Kibana+Marvel的一份极简指南。 前置条件想要安装ES的前提是已经在本机安装了Java环境，在命令行键入1$ java -version 如果正确打印出版本信息则说明已安装Java，否则请到Java官网下载最新版安装即可。 另外，本文使用Homebrew来安装ES，Homebrew是Mac环境里的一种包管理工具，可以方便地进行软件的安装、更新和卸载操作。如果本机未安装，可以使用以下命令进行安装。1$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 完成以上步骤后，本机已具备Java和Homebrew，进入正题。 安装ES &amp; Kibana123$ brew update$ brew install elasticsearch$ brew install kibana 以上命令将ES和Kibana安装到本地，其中Kibana是ES的一个配套工具，可以让用户在网页中与ES进行交互。安装完成后，在命令行键入12$ brew info elasticsearch$ brew info kibana 可以分别看到两个软件的一些安装信息，比如安装路径和配置文件的路径等，后面会用到。 安装MarvelMarvel也是ES的一个插件，能够让你通过Kibana非常容易地监视ES集群的健康状态等信息。最新版的Marvel已经集成到X-Pack模块当中。X-Pack是ES的一个安全框架，可以给网页端访问Kibana加入账号系统，使操作更加安全，更多介绍请移步官方文档12$ cd /usr/local/Cellar/elasticsearch/&lt;whatever version you have&gt;$ bin/elasticsearch-plugin install x-pack 以上命令安装X-Pack模块到本地，至此安装部分完成。 启动ES &amp; Kibana12$ brew services start elasticsearch$ brew services start kibana 启动后可以在本地浏览器访问 ES: http://localhost:9200 Kibana: http://localhost:5601 首次进入Kibana页面时需要输入账号名和密码，默认的用户名是elastic，密码是changeme，可以通过以下命令修改密码123$ curl -XPUT -u elastic 'localhost:9200/_xpack/security/user/kibana/_password' -H "Content-Type: application/json" -d '&#123; "password" : "kibanapassword"&#125;' 如果不想使用账号密码，可以将下面的配置写入ES和kibana的配置文件，配置文件所在目录可以通过brew info xxx查看1xpack.security.enabled: false 重启ES和Kibana后以上配置即可生效12$ brew services restart elasticsearch$ brew services restart kibana 然后可以在Kibana页面中的Dev Tools子页面下直接与ES交互。关于ES的具体命令，请参看《Elasticsearch 权威指南》 祝学习愉快==]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信公众号开发工具汇总]]></title>
    <url>%2F2017%2F11%2F06%2Fwechat-develop-tools%2F</url>
    <content type="text"><![CDATA[前面写了篇入坑指南，介绍了下开发微信公众号的基本流程。最近又捣鼓了一阵，发现这开发工具的选择对于提高开发效率真是有莫大的帮助，所谓“只要工具选得好，月底奖金跑不了”。今天得空，笔者就给各位老哥列举几个绝对能派上用场的小工具，保证没毛病！ 微信公众平台技术文档这货实际上是必需品，没了它，您还真是寸步难行。官方文档包含了一个产品最直接也最全面的说明，在微信公众平台技术文档中，详细说明了微信公众号开发的概念与流程，以及各个接口的调用方法。开发中遇到的大部分问题都可以在这里找到答案。值得称赞的是，这份文档还在一开始给出了一份较为详尽的示例程序，通过代码的方式带着读者走了一遍开发的流程，细致全面又不显得啰嗦，可以说是比较用心了，给写文档的妹子点个赞！ 微信公众平台接口测试账号入坑指南里提到过，当前公众号类型主要分为订阅号和服务号，不同类型账号的主要区别在于接口调用的权限不同，那么如果我们就是想学习下各个接口的调用方法，但手边又找不到一个具有对应权限的公众号该怎么办呢？这时候你可以去申请一个接口测试账号。申请流程很简单，点击网页上的按钮，直接用微信扫码即可。 顾名思义，接口测试账号就是专门为开发人员准备的，用于测试接口调用方法的微信公众账号。和普通的公众号一样，可以在网页上对测试账号进行后台的管理，也可以通过扫描二维码的方式来关注测试账号，进行相应的操作。所不同的是，测试账号的名称和logo是无法更改的，名称就叫“xxx接口测试号”，logo则是个灰色的人头，为的就是把它们和通常的公众号区分开来。很显然，要是能改名改logo，那测试号就可以直接用于实际生产环境中了，也就没有必要再去申请公众号。 微信公众平台接口调试工具当我们在开发一个新功能的时候，通常希望能先预览一下实际的效果，这样可以对整个任务有一个更加感性的认识。而在开发微信公众号时，接口调试工具就能起到这样的作用。接口调试工具提供了一组图形化界面，通过简单地输入一些参数，就可以实现各个接口的调用，并立即在公众号上查看对应的效果。这种交互方式非常直观，也非常高效。此外接口调试工具还可以帮助我们进行debug，当我们在开发中遇到一直无法调通某个接口的情况时，可以将使用到的参数直接复制到接口调试工具的网页上，从而观察运行结果是否符合预期，通过比较两种方式调用结果的异同，我们可以更准确地找到bug所在。当然，关于debug这一点，下文介绍的工具才是真正的利器。 微信web开发者工具入坑指南里提到过，微信网页开发已经成为整个微信公众号开发当中很重要的一分部。事实上，在微信公众号开发中，设置自动回复规则和下拉菜单这两项所能提供给用户的服务非常有限，要想完成一些比较复杂的逻辑交互，就必须实现微信公众号内的网页开发。 网页开发就是指编写一系列的HTML5页面，并在微信公众号中引导用户打开我们开发的页面，从而实现相关的业务逻辑，这一功能使得公众号可以像一个内嵌在微信当中的应用一样，能够实现非常复杂的交互逻辑，而且相比于通常的应用来说更加小巧。 做过前端开发的老哥们对于浏览器中的“检查元素”这个功能一定都不陌生。当下前后端的开发通常是分离的，二者通过API接口进行对接。前端开发过程中为了进行调试，通常会在网页中打开“检查元素”功能来查看后端的回复是否正确，从而发现代码中可能存在的bug。而当我们进行微信web开发时，公众号里的网页是由微信自带的浏览器进行解析的，我们只能看到网页的效果，却无法看到任何有关前后端通信的数据，这样一来，当错误出现时，我们也就无从知道究竟是前端的锅还是后台的锅，这自然会影响开发的效率。微信团队的大佬们自然也想到了这一点，于是便有了web开发者工具这一调试利器。 微信web开发者工具实际上就是个自带“审查元素”功能的微信浏览器。通过扫码的方式，我们可以用自己的微信账号来登录这个软件。在登录之后，它就成为了一个可以在电脑桌面上打开的“微信浏览器”，通过在地址栏输入前端网页的地址，我们可以模拟在手机上的微信公众号中点击了某个网页的行为，当然此时前后端通信的数据也就一目了然。我们可以按照网页上的逻辑进行操作，就好像我们在一个普通的浏览器中所做的一样，简单好用，可以说是非常走心了。 以上就是笔者在捣鼓微信公众号时经常用到的一些小工具，回想起来，它们确实给开发过程带来了很大的帮助，在此分享给各位老哥，希望对各位有所帮助。]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>wechat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优秀的程序员是什么样的？]]></title>
    <url>%2F2017%2F11%2F03%2Fdo-not-trust-user-input%2F</url>
    <content type="text"><![CDATA[在程序员的世界里有一句经典的至理名言：永远不要相信用户的输入。相信很多开发者都有过类似的踩坑经历，所谓“幸福的人都是相似的，而编程的人是幸福的”。 初入职时，作为一名后端工程师，每次实现接口后，老大(我的组长)都会过来帮我瞄一眼，然后提出一堆改进意见，其中最常被提到的一点就是：永远不要相信用户的输入。我不以为意，没怎么去改相关逻辑，这么做的后果就是老大下次再帮我检查时，总会伴随一阵悦耳的争辩声。 Round 1 你这里为什么不加个类型检查？万一接收到的值不是数组怎么办？ 怎么会呢，这些接口类型都是和前端定好的呀。 前端传入的数据是可以被篡改的，万一有人模拟了一个前端请求，发送一个其他类型的变量，那你的程序不就炸了？ 那样的话程序会返回服务器异常，攻击者也不会得到什么有用的信息吧… 是没什么损失，但为什么要给别人留下这么个漏洞呢？ 哦哦… Round 2 这个接口传入的是图片对吧，为什么不检查下图片的大小？ 这个，前端已经检查过了，太大的图片前端会先进行压缩的。 不是和你说过了吗，永远不要相信前端的输入！万一有攻击者模拟前端接口发来很大的图片呢？ 额，不是还有nginx可以挡一道吗？太大的图片应该直接无法响应吧。 nginx的确能做这个，但这些也是需要配置参数的，万一不小心参数设太大了没发现怎么办？ 哦，那就只能接收并保存下来了，不过我们的图片不都放在s3上吗，大一点也没什么关系吧，存储也挺便宜的… 你太天真了！首先，s3也是要花钱的，虽然空间不贵，但流量贵啊，万一真被人发现这个漏洞，他们完全可以把大量的图片通过你这里上传，然后根据返回值里的图片链接去获取。甚至如果有不怀好意的人传了些不该传的东西上去，那咱说不定都要去局里坐坐，这可不是开玩笑。 Game Over 这下我算彻底服了，只好满口答应，然后老老实实把该补的补上。嘴上虽这么说，但心里难免还有点疙瘩，这些都是特殊情况嘛，哪有那么容易就发生。事情总是这样，只要还没在自己身上发生，就会抱有侥幸心理，认为它一定不会发生，等到真的发生了，又来责怪自己当初怎么那么不小心。笔者就有过这么个经历，虽没犯下什么大错，但也足够长点记性了。 话说最近在做微信公众号开发，某天PM(产品经理)姐姐拿着个新需求过来，说是要加一个批量导入历史用户的功能，我扫了一眼开发文档，在用户管理文档中找到了获取用户基本信息这一项，心想不正是这个接口么，于是自信地回了句：“明天下班前给你”，转头就热火朝天地敲起了键盘。 整个流程比较清晰，先通过接口调用凭据access_token获取用户的openid列表，再调用获取用户基本信息接口来得到用户的昵称等信息，再将获取到的信息存到数据库即可。不过，作为一个严谨的开发，当然不能这么草率，还要考虑下效率和安全的问题。微信公众号里的用户动不动就上万，要一个个去获取基本信息那绝对是不妥当的，这一点微信团队的大佬们当然也想到了，所以提供了一个批量获取微信用户信息的接口，甚是方便。 另外，将数据存储到数据库时，当然也不能一条条地存入，这样一不小心得把数据库整挂了。应该在程序里构造sql语句，累计到一定的用户量之后再以批量的方式插入，这样不仅减少了操作数据库的次数，而且直接执行sql语句的方式也更加高效。 考虑完这两点后，就开始敲代码了。手指翻飞间，几个接口函数已经基本完成，打开编译器，一路绿灯，又麻利地打开本地的前端服务，准备开始调试。点击导入历史用户按钮，后端收到请求，调试器里查看，微信正确地返回了用户列表，因为线下的环境只是个测试号，所以只有20人左右，继续点击下一步，用户信息也成功获取，下一步，sql语句执行成功，全部用户导入完毕，到数据库里一看，数据确实都存下来了，搞定！ 接下来，就是将程序上线了。虽然只是个小功能，可一旦要上线都是需要找老大来的，毕竟万一线上的代码真出了问题这锅最后还得到他头上。于是我就跑去找来了他，他当然也知道我今天在开发这个功能，看我不到半天就完成了，还捎带夸了句：完成地挺快呵。我自然是轻扬起嘴角，淡淡地回了句：这活还蛮简单的。 然而，这种笑容很快就消失了，因为我看到坐在我电脑前的老大眉头紧缩，顿觉头顶乌云密布。果然，不到一会儿，就传来了老大的“盘问”。 你直接用sql语句来插入数据的？ 嗯，感觉这样子更方便一点，效率也更快点。 这个想法是没错，但你这里有个问题啊，在构造sql语句的时候，要特别注意单引号的使用，你看你这里在每个变量的两边显式地加入了单引号，那要是变量的字符串里本身就包含单引号怎么办呢？ 啊，变量的值怎么可能会有单引号啊，这一点我没想到诶。 怎么不可能？你这里的值是微信用户的信息对吧，万一哪个家伙无聊在昵称里加了个单引号呢，这完全是可能的，这种时候你的sql语句就会被这个单引号提前封闭，就会产生语法错误，也就无法正常地执行了。更要命的是，这个时候用户单引号后面的部分就成为了sql命令的一部分被执行了，万一来个drop database之类的，再加个单引号把原来的部分还原，那这就成了典型的注入攻击了。到时候你哭都来不及。 哇靠，原来还有这种操作啊，我如梦初醒，不觉后背发凉。之前听老大提起过在php时代著名的注入攻击的案例，没想到今天自己竟差点犯了这个错误，真是罪过。那该怎么解决呢？我向老大请教。 这个其实也挺简单，只要把可能存在的特殊字符给转义就行了，这样它们就不会变成sql的一部分被执行。 嗯，有道理。于是我就噼里啪啦改起来，不一会儿就把该转义的给转义了，老大看完微微点头，然后再次强调说，特别是涉及到数据库的操作时，一定要严格地检查用户的输入，考虑所有可能的情况，防止出现这样的问题。我毕恭毕敬地听着，点头如捣蒜。 不过事情还没完。老大紧接着又指出另一个问题：你在接收到微信服务器返回的用户信息列表时，有检查它的类型吗？ 我有点疑惑，这个类型不是在微信的文档里写好的嘛，只能是JSON啊，难道这也需要检查吗？ 老大貌似看出了我的疑虑，问到：万一用户的信息里确实有一些特殊的字符，没办法用JSON的方式传输呢？是不是需要先将JSON做个序列化再传输呢？而你没有判断返回值的类型，完全按照JSON的格式来处理，这样后面有可能会出错的。 我还是有点疑惑，不就是个昵称嘛，能有什么特别的字符呢？ 老大看了看我，建议我现在去试下微信修改昵称的功能。这不看还真不知道，在改昵称的时候原来可以插入表情的啊，还不止是微信官方提供的表情，而是能添加自己私藏的任意表情，表情是海量的，而JSON能识别的字符集是有限的，这么一来也就自然会出现一些JSON无法识别的字符。 看到这，我算是相信了，于是又把类型检查给加上了，并且当接收到的类型是字符串时，对其进行了处理，消除了里面可能存在的非JSON字符。老大看了看我，这次算是露出了比较满意的表情。 最后，又检查了一遍，为了验证刚才老大的两个想法，我还特意加了一个记录日志的操作，看看接收到的信息到底都是些啥。确认无误后，老大把程序更新到了线上。两三分钟后，更新完成，我迫不及待地尝试了下这个新功能。说来您还真别不信，线上用户的公众号总共有两万多关注者，这些人里面居然真的有人在昵称里使用了单引号，而且这类人还不少，大概三四百人里就有一个。而且返回的用户信息列表居然真的不全是JSON格式的，而是有部分string格式的，将这些string解析后得到的JSON里面，确实包含了一些无法识别的字符。 我看着日志里的结果，又看了看微信公众平台的官方文档，再回头看看老大那挂着浅浅笑容的脸颊，不禁肃然起敬。一方面是觉得尽管诸如微信这样的官方文档也难免会有疏漏之处，不可一味地根据主观意向来判断。再者，则是对老大的远见卓识佩服之至。我记得曾在知乎上看到过一个问题，大意是说 做一个优秀的程序员到底难在哪里？ 答案里有一条是这么写的： 由于你是一个优秀的（或仅仅是经验丰富的）程序员，你可以看出项目代码里存在着的隐患。你选择防患于未然，修复这些问题，但由于问题并没有真的发生，你所做的一切，在不那么优秀的程序员同事的眼中（以及老大眼中），看起来并没有什么产出。 诚哉斯言。回想起先前的经历，要不是老大及时指出代码里可能存在的错误，那肯定是要出问题的，虽然这一次不一定导致什么严重的后果，但若问题不除，迟早要吃大亏。此时老大已经起身准备离开了，他还有一大堆的事情要忙呢。不过在临走前，他又一次嘱咐了我：永远不要相信用户的输入。 嗯，这次我是真的记住了。望着老大远去的背影，我在心里默念到。 大概，这就是我心目中优秀程序员该有的样子。 参考链接 做一个优秀的程序员到底难在哪里？ - Van Bruce的回答 - 知乎]]></content>
      <categories>
        <category>idea</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[手把手教你入门微信公众号开发]]></title>
    <url>%2F2017%2F11%2F01%2Fbasic-wechat-develop%2F</url>
    <content type="text"><![CDATA[这是一篇关于微信公众号开发的入门指南，较为详细地介绍了开发微信公众号的基本原理，并且有相应的代码实现。如果您正打算要做公众号开发，却又苦于找不到一份简洁明了的入门级教学文档，那么这篇博客应该能解决您的问题。 缘起 近日腾讯发布2017年中报，报告中指出，腾讯二季度实现营业收入566.06亿元，经营盈利、期内盈利分别达到225.6亿元和182.54亿元。按照当前利润与员工数估算，腾讯员工的平均年薪达到80万… 尽管很多人吐槽王者荣耀里的小学生太坑爹，但不得不承认，近年来腾讯的变现能力确实强大地吓人。这之中微信和QQ作为用户的入口，起到了很大的作用。特别是微信，已然是一款装机必备的全民软件，如何借助这个庞大的平台搞点事情，分享下微信带来的用户红利，也就成为一件很值得研究的事。微信公众号是个人或者企业的一个宣传平台，通过开发微信公众号，可以给关注公众号的用户提供更多定制化的服务，进一步可以将服务转化为效益。本文旨在给正准备做微信公众号开发的朋友分享一点经验，从而尽快熟悉微信公众号开发的整体流程。在此基础上可以继续去学习一些高级的开发技巧（比如微信支付、账单系统之类的），让自己的公众号更加地精(zhi)美(qian)。 磨刀不误砍柴工微信公众号大家肯定都用过。目前微信公众号主要分为订阅号和服务号，每种账号又分为未认证和已认证，它们的差别主要在于具有不同的接口权限，下图（引用自微信开发实战系列）是一些例子： 总体来说，服务号权限 &gt; 订阅号权限，认证账号权限 &gt; 未认证账号权限。申请订阅号比较简单，服务号相对复杂点，另外要认证的话还要额外提交一些材料。我们可以根据不同的业务需求去申请不同类型的账号，基本上常用的权限列表已经可以满足大部分的场景。 开发微信公众号本质上和通常的网站开发并无区别。当我们进入一个公众号页面之后，我们可以向公众号发送文字、语音、图片等消息，也可以通过点击页面下方的菜单触发相应的功能。那么开发者与微信用户究竟是怎么进行交互的呢？实际上我们在公众号里的所有操作，都会发送到微信的服务器上，微信服务器将这些动作的具体含义按照一定的格式进行封装后，发送到微信公众号所对应的服务器上（这个服务器的地址可以由开发者在微信公众号的后台进行配置），开发者通过编写代码来处理不同的用户行为，并将处理后的结果按照一定的格式返回给微信服务器，再由微信服务器发送到微信公众号里面，从而完成了一次交互过程。在这里借用方倍老师博客中的一张图片来展示下这个过程，可以帮助大家理解地更清楚： 到这里我们可以知道，所谓的微信公众号开发，其实就是编写业务代码来处理用户的动作请求。这里面会涉及到和微信服务器之间的通信，也就涉及到一些安全认证方面的知识，后文会通过一个实际的例子进行说明。现在，就让我们来看看具体的流程吧。 巧妇难为无米之炊开发微信公众号需要准备以下两样食材： 微信公众号微信公众号可以在微信公众平台的官网上申请。前文说过，微信公众号分为几种类型，不同的类型具有不同的权限，具体的权限列表可以查看微信公众平台技术文档。值得注意的是，现在已经不再支持个人类型的公众账号申请微信认证。申请的过程无非是填写下邮箱和信息，建议使用QQ邮箱，毕竟是自家的东西。 服务器由于我们的服务器需要与微信服务器进行交互，因此必须能够让微信服务器可以访问到。很多公司都提供了云服务器租赁，价格不一，可以自行申请，细节在此不表。如果不想花钱申请，也可以使用一些外网穿透工具，将本地的IP暴露到公网中供外部访问，具体的工具请自行百度，不过大部分软件稳定性无法保证，而且分配的域名经常改变。个人建议还是申请一台服务器比较方便，等以后公众号运营良好开始涨(ying)粉(li)了，这些都不是事~ 撸起袖子加油干以下是详细步骤： 开启公众号开发者模式为了让微信服务器知道开发者服务器的存在，必须在公众号后台进行相应的配置。(1) 登录公众平台官网，找到左边功能栏的最下方，有一个基本配置的选项 (2) 点击基本配置按钮，在右边的页面中填写服务器的相关信息。其中URL填写http://外网IP:端口号/wx，这里外网IP是服务器的外网IP地址，端口号固定填写80。Token可以自由填写，用于两个服务器之间的验证。具体见下图： (3) 点击提交按钮，提示配置失败。这是自然的，因为我们还需要在开发者服务器上进行配置，才能完成验证的过程。 (4) 前面在配置微信公众号时为什么提示失败呢？在此我们有必要探究下这个认证过程。当我们点击了提交后，微信服务器会向我们所填写的那个URL发起一个GET请求，并携带以下几个参数：timestamp, nonce, echostr, signature。其中timestamp是一个时间戳，nonce是一个随机数，echostr也是随机数，这几个都很普通，重点在于signature，它的生成方式是将nonce、timestamp和token（也就是我们在网页中配置的TOKNE）三个字符串按照字典序排序后，对排序后得到的字符串数组使用哈希加密算法得到。我们的服务器在收到这个GET请求后，提取对应的参数，并按照前面说的方式生成hashcode，如果这个值与参数中的signature相同，那么我们就将echostr返回给微信服务器，否则返回空值。微信服务器收到这个echostr之后，验证这个值与它发送的echostr值是否相同，如果相同，说明这个值的确是由我们的服务器返回的，从而完成验证，今后所有的信息就都可以发送到这个服务器地址上。这里面涉及到了一些安全认证的相关知识，有兴趣的朋友可以去查阅更详细的资料。总的来说，就是让通信的双方都能够确认对方的真实身份。以下是认证部分的主要代码，使用Python2.7和web.py框架编写： 编写服务器业务逻辑前面我们完成了微信服务器与开发者服务器的相互认证过程，接下来我们需要编写业务逻辑代码来处理微信服务器发送过来的信息。以文本消息为例，当用户在公众号页面发送了消息后，微信服务器会将这条消息封装成如下的XML格式，并将其作为请求的内容向开发者服务器发起一个POST请求： 各个字段的具体含义就如字段名所示，比较直观。我们首先需要解析这个XML对象，并提取出各个字段用于后续的处理： 解析之后，我们可以在主函数中根据消息的不同类型，来调用不同的处理函数得到相应的处理结果，然后我们要将处理结果封装成同样的XML格式返回给微信服务器，封装XML对象的代码如下所示（以文本消息为例）： 至此，我们就完成了一个简单的回复流程（虽然目前这种只能回复文本消息==）。 更上一层楼以上就是一个基本的微信公众号开发流程。当然，想要让我们的公众号变得多姿多彩，需要掌握的内容还有很多。比如 (1) access_token：前面我们所做的实际是被动回复消息，微信服务器发起POST请求，我们将处理后的内容借由微信服务器返回给用户。如果我们需要主动地和用户进行交互，比如主动地向用户发一条消息，我们就需要调用微信公众平台提供的相应接口，并且需要主动告诉微信服务器我们的身份，这是通过access_token实现的。 access_token是微信公众号的全局唯一接口调用凭据，公众号在调用各个接口时都需要使用access_token。 如上所述，在我们调用各个接口前，需要先使用公众号的appid和appsecret信息（这两个值可以从微信公众号的网页上查看）向微信服务器请求获取access_token，然后带着这个值去调用微信公众平台提供的接口，实现相应的功能。 (2) 微信网页开发：网页开发就是指编写一系列的HTML5页面，并在微信公众号中引导用户打开我们开发的页面，从而实现相关的业务逻辑，这一功能使得公众号可以像一个内嵌在微信当中的应用一样，能够实现非常复杂的交互逻辑，而且相比于通常的应用来说更加小巧。 从这里出发以上就是本文的主体内容。楼主经验尚浅，斗胆提笔撰文，有不当之处欢迎各位指出。本文主要是一个入门的简介，后续的开发还有很多内容要学，以下列出一些个人认为比较不错的文档和资料，楼主也从中学到了很多，在此感谢各位作者。 (1) 微信公众平台技术文档(2) 方培工作室-微信公众平台开发教程(3) 微信开发者联盟(4) 微信开发实战系列 本文中的代码已上传到github，里面包含了微信公众号一些常用功能的实现，仅供参考：微信公众号开发示例程序]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>wechat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我们都曾行走在白夜里]]></title>
    <url>%2F2017%2F11%2F01%2Fbai-ye-xing-note%2F</url>
    <content type="text"><![CDATA[当我合上书本，再次看到封面上牵着手的小男孩和小女孩时，一种莫名的难过翻涌而来，投射到墙上的阴影仿佛要将整个房间笼罩。那里本该洒满阳光。 东野大叔的叙事风格宛若天马行空，这一点在《解忧杂货店》中就充分感受过，相比起来，《白夜行》可谓有过之而无不及，乃至于第一遍捧起书时到第五章就看不下去了，我已经忘了前面都说了啥。我是怀着一点猎奇的心来的，顶尖的推理小说作家，悬疑的杀人案件，如潮水般的好评，这足以让人坚信这本书能给人带来精彩的阅读体验。 但很显然，那时的我并没感受到。紧张的案件叙述部分在第一章的末尾戛然而止，接下来时光不断往前推进，各色人物一个接一个出现，发生的故事似乎没什么联系，那桩案子也宛如投向湖中的石子，随着波纹的远去逐渐淡出人们的视野。 难道就这样了吗？我不禁暗自揣测。合上书本，我瞅了眼封面，两个小孩子携手同行，他们的影子被拉得老长。这幅画有什么含义呢？我实在搞不懂。但东野大叔应该不会让人失望吧。 于是我又把书翻到了第一页。 东野大叔也确实没让人失望。 天网恢恢，疏而不漏。尽职的老刑警追了十九年，终于亲手将真凶绳之于法，而另一位主谋唐泽雪穗，则在失去唯一的精神支柱后彻底卸下了伪装。 她一次都没有回头。 这是全文的结尾，也是最精彩的地方之一。初看起来，这句话似乎进一步表现了雪穗的心狠手辣，对于和自己相依为命的伙伴的死也毫不在乎，但考虑到当时的场景，一个“陌生人”在自己店门口死亡，换做普通人应该会和她的店员们一样惊慌失措，而她却没有丝毫的情绪变化，这恰恰说明她此刻内心的波动之大，甚至让她忘记了身上一直披着的那层伪装。以这种方式接受惩罚，大概是最令人满意的结局。 东野大叔的确很擅长叙事，当看完全书再把前面的故事串起来时，才发现原来两位主角犯下了如此多的罪行，可谓千夫所指。这种人性的恶，在主人公身上被展现地淋漓尽致。 但整本书仅仅就是为了描述人性的恶吗？ 关于整个故事，有一个颇具争议的问题：该不该同情雪穗和亮司？ 我想，纵使不被同情，也不该把全部的错怪罪到他们身上。任何事情的发生都有个缘由。善恶终有来处。 出身贫苦，父亲早逝，与柔弱的母亲相依为命，被迫和陌生的大叔发生关系，这是唐泽雪穗的童年，也是导致其性格变化的直接原因。在那个破烂的潮湿的小屋子里，她度过了人生中本该最美好的一段时光，但留给她的却只有无尽的黑暗。母亲忙于生计，卑躬屈膝还要处处遭人白眼，连带着她一起受尽委屈。最可恨的是，为了生活，亲生母亲居然把她交易给胡子拉碴的大叔作为性工具，那是怎样一种无奈与痛苦。雪穗向母亲抗议过吗？我想大概是有的。但在母亲的恳求或是诱导下，她不得不接受这样的现实。从那一刻起，她的心里就已经埋下了邪恶的种子，随着时间的推移，慢慢生根发芽。 我从来就没有太阳，所以不怕失去。 正如她自已所说，她从一开始就是个身处黑暗的人，心中只剩欲望和仇恨。 桐原亮司的幼年也不快乐。虽然不愁吃穿，但风流成性的母亲和患有恋童癖的父亲显然没有给过他任何的关爱。他们不关心他每天都去了哪，干了啥，只管自己过得快活。他在家里没有任何人可以交流，于是他跑了出去，和同龄小朋友们玩耍是他少有的慰藉。直到他遇见了雪穗，他找到了一个可以说话的人，他把自己心爱的剪纸拿给她看，他和她经常相约在图书馆见面。多么美好的事啊，有这么可爱的玩伴。 他们本该这样长大。 当桐原拿起剪刀戳向父亲时，他一定花光了全部的力气。那种义无反顾，就像是去完成一件多么伟大的使命一般。只不过，此时的天空已被白夜笼罩。 从此枪虾和虾虎鱼开始了彼此依赖的生活。他们结伴而行，在白夜里摸索。 亮司最后强奸了美佳，变成了他父亲那样的人。雪穗安排了这一切，变成了她母亲那样的人。 这是小说中最具戏剧性的地方。受害者最终成为了害人者，新的受害人又是否会延续这样的轮回？循环往复，归途何处？ 每当我们在报道里看到，一些青年乃至少年犯下的极恶罪行，总是会习惯性地感叹一番人心的险恶，家教的缺失，然后再将《未成年人保护法》痛骂一番。罪犯固然可恨，该受到应有的制裁，但我们更应该考虑到，扭曲的心灵并非与生俱来的，黑暗的背后更需要阳光的照耀。 我曾认识这样一个女孩。 她出生在一个农村家庭，父亲嗜赌如命，在输光了家里所有的积蓄后，抛下她和母亲独自离去，那时她只有两岁半。母亲不堪重负，也狠心离去，将她留给了年迈的爷爷奶奶。村里的孩子经常欺负她，嘲笑她是个没人要的小孩，她很难过，又不知怎么反驳，就只是一味地哭。二老也没什么法子，就让她待在房间里，不准她出来。从此每天陪伴她的就只有洋娃娃和天花板，甚至连外面的蓝天白云都看不到。 后来她上了学，总是一个人坐在最角落的位置上，无心上课，成绩也一塌糊涂。后排调皮的男孩子经常拿她开玩笑，有的还动手动脚，她拼命想要反抗，但双拳难敌四手，她还是会经常受到欺负。终于有一天，她忍不住了，在放学路上捡起一块砖头狠狠扔向了其中一个人的头。 男孩受了重伤，家人找上门来，索要赔款，声称不赔钱就抓人。二老一边哭一边气，骂她是个没用的东西，和她爸一样，就知道干坏事。嘴上虽然骂娘，但钱还是得赔，总不能真让个十来岁的女娃子去蹲派出所。亲戚朋友们凑了点钱，把这事儿算是盖了过去。 后来倒也真平静了一阵儿，半年多没再闹事儿，估计是学校里的小伙儿们也心有戚戚，这姑娘惹不得。 那年春节，我爸妈觉得她家怪可怜的，又是街坊邻居的，就让我送点东西去她家。我把一篮子吃的提到厨房，和她奶奶聊了会儿家常。出门的时候，我不经意间回了个头，从旁边小房间里传来一道阴冷的光，差点没把我吓到。 她一个人蜷缩在房间的地板上，靠着床沿，边上是一台老旧的小彩电。她的目光朝我这边汇聚，眉头有一点点皱，紧咬着嘴唇，就那么死死地看着我。 我晃了晃神，匆忙地溜出大门，脚步飞快。 那是我一辈子忘不掉的眼神。 再后来，我去县城里上高中，少有机会回家，也就没再见到过她。只是某一年回去的时候听妈提起过，她好像很早就辍学了，离开了那个家，不知道去了哪。 天大地大，何处是家。 细想下这事儿，她的父亲肯定是要负首要责任的。父亲的恶习导致了家庭的破裂，给年幼的孩子造成了不可挽回的伤害。如果不想养家，又为何要成家？再往上找，父亲的恶习又是怎么造成的呢？大概是早年时不学无术，又没有一技之长，甚至懒惰地连活也不想干，于是就想找点快捷的方法。你说这该怪他的父母吗？可他们大概会说，我们要赚钱养家啊，哪有时间管孩子，只要他老老实实不给我们惹麻烦就行。他自己好赌，那是他天生的，这混账小子。 呵，养家糊口，不肖子孙，多么冠冕堂皇。 总有一些人，喜欢把孩子当做自己的附属品，只要给口饭吃给个衣服穿，就算是养他了。他们不懂得什么是教育，甚至不会教孩子基本的行为礼仪和道德廉耻，反正命是他的，爱咋咋地，老子当年也是这么过来的，不照样活得好好的？ 愚昧和无知，比黑暗本身更可怕。 想再讲个事儿。 近年来有个词在网络上出现的频率不断提升，就是“抑郁症”。 “某当红男星因抑郁症在家中服毒自杀，花样年华就此陨落。” “某中学女生因难忍同学的流言蜚语，终日恍惚不定，最后留下一纸遗书，从十楼的家中跳下。” 伴随着抑郁症而出现的，还有一种叫做“网络暴力”的现象。某人被爆“黑料”，全网通告，好事者火速赶往现场，不论是非曲直，群起而攻之，或图一时之嘴快，或蹭一时之流量，他们坚信法不责众，大家都说黑的肯定错不了。当事人还未晃过神，就要迎接漫天的声讨。理智者顺藤摸瓜，找准源头，可使烟消云散。更多的人则选择沉默，听之任之，不到数日，或在沉默中爆发，或在沉默中消亡。前者伤人，后者伤身，只留下一声叹息，以供凭吊。 而我们，或许就曾是众多好事者中的一个，尽管有时连我们自己可能都没意识到。 少一点刽子手，多一点摸摸头。我们没办法要求别人如何如何，但至少自己能做到不轻信，不盲从，凡事有个理性的判断，而非人云亦云。毕竟，思维能力是人区别于动物的最大特点，如果连独立思考都不会了，又与动物何异呢？ 愿白夜不再笼罩，黑夜里也能传来欢笑。]]></content>
      <categories>
        <category>reading</category>
      </categories>
      <tags>
        <tag>东野圭吾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Mac上搭建基于Hexo的个人博客网站]]></title>
    <url>%2F2017%2F10%2F29%2Fcreate-hexo-blog%2F</url>
    <content type="text"><![CDATA[Hexo是一个快速、简洁且高效的博客框架，特别适合于部署静态的博客网站，更多介绍请移步官方文档。本文主要记录下笔者在Mac上实际的部署流程，包含期间遇到的坑和一些基本用法的介绍。 环境配置安装Hexo前需要先安装Git和Node.js 1. Git在Mac上安装Git最方便的方式是使用Homebrew，它是Mac上的一种包管理工具，能方便地安装和卸载软件。1$ brew install git 安装结束后在命令行输入git后运行，如果屏幕上出现git命令的使用帮助，说明安装成功。 在后文中可以看到，笔者借助github的网站作为个人博客网站的代理服务器。在进行博客网站部署时，会频繁涉及到本地与github网站的通信，为了免去每次通信时都要输入用户名和密码的烦恼，我们可以将本地的一组ssh-key传到github网站上，作为通信的凭据。 SSH是一种网络协议，全称Secure Shell，主要用于计算机之间的加密传输。以下介绍相应配置。 首先检查本地是否已存在ssh-keys1$ ls -a ~/.ssh/ 以上命令列出当前用户主目录下的.ssh目录中的所有文件，如果存在id_rsa和id_rsa.pub则跳过下一步，否则需要手动生成一组ssh-key 执行以下命令生成一组公/私钥，其中your_email@example.com需要替换成你自己的邮箱地址。1$ ssh-keygen -t rsa -C "your_email@example.com" 生成的文件默认会放在之前提到的.ssh目录中，我们需要获得公钥的值，在命令行输入1$ cat ~/.ssh/id_rsa.pub 该命令将公钥文件中的值，也就是一个很长的字符串输出到命令行中，复制该值备用。 接着登录github网站，单击右上角的头像，依次点击Settings -&gt; SSH and GPG keys -&gt; New SSH key 之后，会出现个文本框，在Title那一栏填写一些用于标识当前机器的信息，然后将前面复制的公钥值粘贴到Key那一栏，点击Add SSH key，即完成了添加操作，今后可以使用ssh地址直接从你的github仓库clone项目到本地，也可以将本地的修改直接push到github上，非常方便。 2. Node.jsNode是javascript的一种运行时环境，也是近年来非常流行的一门技术。安装Node.js的最佳方式是使用nvm。在命令行输入1$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.29.0/install.sh | bash 这条命令通过curl下载install.sh脚本，并执行脚本。待执行完成后，它会把nvm命令的执行路径放到~/.bashrc文件里，我们可以用cat命令来查看一下1234$ cat ~/.bashrcexport NVM_DIR="/Users/gao-yimei/.nvm"[ -s "$NVM_DIR/nvm.sh" ] &amp;&amp; . "$NVM_DIR/nvm.sh" # This loads nvm 确认存在以上配置后，通过执行source命令来使得环境变量生效1$ source ~/.bashrc 至此我们就把nvm安装好了，可以通过以下命令查看nvm版本号12$ nvm --version0.29.0 如果能正确打印出版本信息就证明nvm已经安装成功。接着通过执行以下命令来安装Node.js1$ nvm install stable 如果安装期间遇到权限问题，可以改用sudo的方式重新运行。 安装完成后，在命令行键入12$ node -vv7.1.0 如果能够正确打印出版本信息，则说明安装成功。 安装Hexo完成准备工作后，可以正式开始安装Hexo。在命令行输入1$ sudo npm install -g hexo-cli npm是Node.js自带的一个包管理工具，用于安装和卸载Node模块。上面的命令将Hexo这个模块以全局的方式安装到我们的电脑中，是Hexo官方推荐的方式。但笔者在运行这条命令时，出现了如下的错误12345678910111213141516npm ERR! Error: EACCES: permission denied, mkdir '/usr/local/lib/node_modules/hexo-cli'npm ERR! at Error (native)npm ERR! &#123; [Error: EACCES: permission denied, mkdir '/usr/local/lib/node_modules/hexo-cli']npm ERR! errno: -13,npm ERR! code: 'EACCES',npm ERR! syscall: 'mkdir',npm ERR! path: '/usr/local/lib/node_modules/hexo-cli',npm ERR! fstream_type: 'Directory',npm ERR! fstream_path: '/usr/local/lib/node_modules/hexo-cli',npm ERR! fstream_class: 'DirWriter',npm ERR! fstream_stack: npm ERR! [ '/usr/local/lib/node_modules/npm/node_modules/fstream/lib/dir-writer.js:35:25',npm ERR! '/usr/local/lib/node_modules/npm/node_modules/mkdirp/index.js:47:53',npm ERR! 'FSReqWrap.oncomplete (fs.js:82:15)' ] &#125;npm ERR! npm ERR! Please try running this command again as root/Administrator. 明明是以sudo方式运行的啊，为什么会出现权限错误呢？笔者一头雾水，最后还是在某度上找到了一个解决方案。执行以下代码1$ sudo npm install --unsafe-perm --verbose -g hexo 大意就是忽略一些安全方面的警告，强制安装。最终成功安装上了。 使用Hexo基本用法Hexo默认已经配置好了基本的选项，通过以下几步简单的操作就可以获得一个示例的博客网站。 终端切换到一个你准备用来搭建博客的目录，然后执行命令1$ hexo init myblog 其中myblog将会作为博客网站的本地主目录，该命令对文件夹进行了初始化，生成了一些建设网站所必须的材料。切换到myblog文件夹下，执行以下命令1$ npm install 前面提到过，npm install是用来安装Node.js模块的，当这个命令不带参数时，它将会读取当前目录(也就是myblog目录)下的package.json文件，并按照里面的描述来安装，所有的模块都会存在当前目录下一个名为node_modules的文件夹下。 等待安装完成后，仍在当前目录下，执行以下命令，开启Hexo服务器1$ hexo start 若一切正常，则命令行会打印出如下的提示信息12INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 该信息表示Hexo服务器已经在本地的4000端口运行了。打开任意浏览器，在地址栏输入localhost:4000后回车，即可看到默认的欢迎页面。 修改配置默认页面上信息都是关于Hexo的，我们要将其改为自己的信息。在myblog目录下，使用ls命令查看该目录下的所有文件12$ ls_config.yml node_modules package.json scaffolds themes db.json package-lock.json public source yarn.lock 其中_config.yml保存了与网站相关的基本配置。使用vim打开，可以看到如下信息123456789101112# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: 你的博客名称subtitle:description: 你的博客介绍或者座右铭author: 你的昵称language: zh-Hanstimezone:... 最开始的部分就是关于网站的标题、作者和简介等信息，这里可以根据个人的情况填写，其中language那一栏填写zh-Hans表示网站采用简体中文。填写时注意各个字段的冒号后必须要空一格再填具体内容，填写完毕后保存即可。 接着我们来看一下Hexo中一项很实用也很强大的工具，那就是主题。大家之所以喜欢写个人博客，一个很重要的原因就是它的自由性，我们可以往博客上添加任何个人喜欢的元素，也可以根据自己的喜好来定制网站的背景、样式、配色等。Hexo为我们修改网站的风格提供了一种非常便捷的方法，只需要简单的几步，就可以将我们的网站修改成一种指定的风格，我们还可以自己定制喜欢的模板。下面以Hexo官网上提供的NexT主题为例，介绍下如何为我们的博客更换不同的主题。 在myblog目录下执行以下命令1$ git clone https://github.com/iissnan/hexo-theme-next themes/next Hexo中的主题实际上都是由不同的网友贡献的，以上命令将该主题所对应的github上的项目克隆到myblog目录的themes目录下。 接着打开myblog目录下的_config.yml文件，找到theme配置项，将对应的值改成next1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next 保存后退出。仍在myblog目录下，依次执行以下指令12$ hexo clean $ hexo generate 两条命令分别是清除缓存文件以及重新生成静态文件。重新启动Hexo服务，即可看到next主题风格的博客页面。 更多设置添加个人头像有了主题之后，我们可以在网站中设置侧边栏个人头像。在myblog目录下，打开themes/next/_config.yml文件，找到avatar配置项，将值设为头像的地址。该地址可以是一个完整的图片链接，也可以是一个站点内的相对路径。如果使用前者，为了保证图片链接的有效性，可以先将图片上传到github上再使用对应链接，而对于后者，则需要先将图片放到themes/next/source/images目录下，再使用相对路径引用。以下配置是一个采用相对路径的示例1234# Sidebar Avatar# in theme directory(source/images): /images/avatar.gif# in site directory(source/uploads): /uploads/avatar.gifavatar: /images/coolboy.jpg 添加标签Hexo默认只开启了两个标签：首页和归档，我们可以添加一些常用的其他标签，比如标签、分类和关于。先打开/themes/next/_config.yml文件，找到menu配置项，如下所示123456789101112131415161718menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true home: home about: user categories: th tags: tags archives: archive 可以看到默认情况下只有home和archives前面没有#号，其他项都没注释掉了，因此我们要先把准备开启的标签前的#号给去掉，并且在下方menu_icons配置相应的值，这里配置的icon也就是网页上展现的对应的图标，实际上是由Font Awesomo网站提供的，涵盖了众多常用的网站图标。配好之后保存退出。 然后我们来创建需要的页面。首先是about页面，在myblog目录下运行命令1$ hexo new page "about" 这条命令会在source目录下新建一个名为about的文件夹，并生成一个index.md文件，使用任意的markdown编辑器打开后编辑，可以写上个人的介绍以及一些自己想说的话，完成后保存退出，这样一来about页面就做好了。 接下来是categories页面，同理，先在命令行运行1$ hexo new page categories 然后编辑刚刚创建的index.md文档，将页面类型设置为categories即可，Hexo会自动将带有不同类别标签的文章进行分类归档展示123456---title: Categoriesdate: 2017-10-27 17:27:06type: "categories"comments: false--- 这里还有个comments字段被设置为false，这是因为Hexo的博客可以外接一些第三方的评论系统，默认在所有页面都会显示，而我们一般只希望评论显示在文章主页面的下方，因此此处将评论给关闭。 最后是tags页面，同理先在命令行创建页面，然后编辑页面，将页面的类型设置为tags即可，Hexo的主题系统会自动地在这个页面中显示标签云1$ hexo new page "tags" 添加Read More按钮默认情况下我们的文章会在主页以全部展开的形式呈现，但我们通常希望在主页上每篇文章只显示一部分，这样既显得简洁，又可能让读者看到更多的文章，便于读者的判断。想要做到这一点很简单，只要在文章对应的markdown文档中，按照下图所示插入一句特殊的代码到我们想要进行截断的任意位置即可12345More info: [Server](https://hexo.io/docs/server.html)&lt;!--more--&gt;### Generate static files 这样首页上的文章只会显示之前的部分，然后会有一个阅读全文的按钮，点击之后再进入文章的主页面，看起来非常舒服，也很合理。 经过上面的这些设置后，我们就能得到一个看起来不错的博客网站了，可以运行Hexo服务，在浏览器上实时查看我们的网站，现在的情况就像这样 通过github发布现在我们已在把网站在本地搭起来了，为了让别人能通过互联网访问我们的网站，还需要将其发布到网络上，这里我们以发布到github上为例。 首先，我们要在github上新建一个Repository，名称固定为1yourNickName.github.io 其中yourNickName指的是你的github账户昵称，注意必须按照这个规则来命名。然后我们编辑myblog/_config.yml文件，在文件的最后几行找到deploy设置项，按照下面的方式进行修改123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:coolBoyGym/coolboygym.github.io.git branch: master 其中的repository字段需改成你自己的giuhub项目对应的地址。 修改完成后，在blog目录下依次运行以下命令12$ hexo generate$ hexo deploy Hexo会先在本地生成静态的网页文件，然后将所有文件推送到github上对应的项目中。一切正常的话，我们就可以通过下面的网址访问个人博客，应该能看到和本地一样的效果1https://yourNickName.github.io 到此，我们就算是真的搭建好一个简单的博客网站了，赶快请你的小伙伴们来看看吧~ 新建文章当我们想要写一篇新博客时，先执行以下命令1$ hexo new "My-New-Post" 其中My-New-Post是你想新建的博文的名字，这条指令会在myblog/source/_posts文件夹下新建一个名为My-New-Post.md的文件，我们可以使用任意的markdown编辑器来打开它进行编写，完成之后，我们可以先在本地查看下效果，确认无误后，同样通过之前的两条命令来将这篇新的博文发布到github上12$ hexo generate$ hexo deploy 关于markdown编辑器，笔者使用的是Cmd Markdown，界面比较简洁，可预览，功能也较全，值得推荐~ 以上就是本文的全部内容，涉及到了Hexo的一些基本操作，当然它的强大还远不止于此，通过集成各种第三方的服务，可以让我们的网站变得更加有趣，这个就有待读者们自己探究了，有什么好玩的第三方工具欢迎告诉我。 参考链接 与佳期的个人博客 Hexo NexT github/iissnan]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F10%2F28%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>daily</category>
      </categories>
  </entry>
</search>
